ğŸš€ Pseudocode-to-C++ Code Generator using GPT-2 + LoRA

An intelligent AI system that converts natural pseudocode descriptions into fully executable C++ programs â€” fine-tuned using GPT-2 with Parameter-Efficient Fine-Tuning (LoRA).

Built by Muhammad Naeem and Aneela Bashir.

âœ¨ Overview

This project bridges the gap between human logic and machine implementation. By fine-tuning GPT-2 with LoRA, we created a lightweight yet powerful model capable of generating context-aware, structurally correct C++ code from simple English-like pseudocode instructions.

The system is deployed as a free Streamlit web app, allowing students and developers to generate code instantly.

ğŸ’¡ Key Highlights
ğŸ”¹ 1. Dataset Processing

Used 18,356+ pseudocode-to-code pairs from the SPOC dataset.

Handled:

Multi-line C++ code

Indentation + brace alignment

Syntax variations + formatting inconsistencies

Added custom markers:

<|pseudo|> â€¦ <|code|>

ğŸ”¹ 2. LoRA-Based Fine-Tuning

Applied LoRA to GPT-2 for efficient training.

Only 1.2% trainable parameters
â†’ 1.5M trainable out of 126M total.

Trained for 5 epochs with:

FP16 mixed precision

Gradient accumulation

Early stopping

Google Colab T4 GPU

ğŸ”¹ 3. Smart Training Pipeline

Custom tokenization + special tokens

Masked pseudocode tokens so the loss is only computed on generated C++

Beam search decoding (num_beams=5) for high-quality outputs

Automatic and manual evaluation

ğŸ“Š Evaluation Results
Metric	Score
BLEU	13.93
Approx. CodeBLEU	0.405
Code Quality (Manual)	85%
Structural Accuracy	82%
Generation Success	100%
ğŸ§  Capabilities of the Model

âœ” Generates syntactically correct C++ code
âœ” Proper brace management ({} alignment)
âœ” Handles loops, conditionals, functions, I/O
âœ” Understands multi-step logic
âœ” Context-aware variable usage
âœ” Fully deterministic or creative output (beam vs sampling)

ğŸ–¥ï¸ Live Demo

ğŸ¯ Try the web app here:
ğŸ‘‰ https://lnkd.in/deRaZdes

ğŸ“˜ Documentation & Code

ğŸ“„ Full Project Breakdown:
ğŸ‘‰ https://lnkd.in/dbUq5yRJ
ğŸš€ How It Works

User enters pseudocode in plain English.

Model converts to structured <|pseudo|> ... <|code|> format.

GPT-2 (fine-tuned with LoRA) generates accurate C++ code.

Output appears instantly in the Streamlit interface.

ğŸ› ï¸ Tech Stack

GPT-2 (Hugging Face Transformers)

LoRA (Parameter Efficient Fine-Tuning)

PyTorch

Streamlit

Beam Search Decoding

Google Colab GPU


â­ Future Improvements

Support for Python, Java, and C

Add CodeBLEU official evaluation pipeline

Integrate syntax error auto-fixing

Add function decomposition and multi-file generation

ğŸ“¢ Contributions

Pull requests and enhancements are welcome!
If you find bugs or have feature requests, open an issue in the repository.

ğŸ“œ License

This project is released under the MIT License.
